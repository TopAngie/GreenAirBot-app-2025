services:
  webui:
    build: 
      context: .
      dockerfile: Dockerfile.webui
    ports:
      - "5000:5000"
    environment:
      - LM_API_URL=http://ollama:11434/v1

    depends_on:
      - ollama



  ollama:
    build:
      context: .
      dockerfile: Dockerfile.ollama
    container_name: ollama
    ports:
      - "1234:11434"
    volumes:
        - ollama_models:/root/.ollama  # <--- Keeps models across restarts
    environment:
      - OLLAMA_HOST=0.0.0.0
volumes:
  ollama_models: